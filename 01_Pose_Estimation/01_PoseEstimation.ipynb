{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pose Estimation (자세 추정)\n",
    "# 인공지능 및 컴퓨터 비전 기술을 사용하여 이미지나 비디오에서 인간의 포즈를 감지 및 추정하는 기술\n",
    "# 인체에서 중요한 Key point의 위치를 찾는 알고리즘 ex) 머리, 어깨, 팔꿈치 등\n",
    "\n",
    "# 자세 추정 형태\n",
    "# 1. Skeleton-based\n",
    "#   주요 부위를 중심으로 찾음 -> 신체 위치 찾기에 유용\n",
    "#   but 전체적인 모양, 부피는 알기 어려움\n",
    "# 2. Contour-based\n",
    "#   신체의 전체 모양을 알 수 있다는 장점이 존재\n",
    "# 3. Volume-based\n",
    "#   3D 자세 추정에 사용되는 Model\n",
    "\n",
    "# 딥러닝의 경우 한 사람의 자세를 추정하는 작업은 잘함\n",
    "# but 여러 사람이 존재하여 다양한 자세를 취하거나 서로 겹칠 경우 복잡해지고 계산 시간이 오래걸림\n",
    "\n",
    "# 이를 해결하기 위한 방식\n",
    "# 1. Top-down\n",
    "#   사람을 탐지 후 탐지 결과를 바탕으로 인체 주요 부위를 찾아 자세 추정하는 방식\n",
    "#   큰 거에서 쪼깨기\n",
    "# 2. Bottom-up\n",
    "#   전체 이미지에서 인체 주요 부위들을 먼저 찾은 후 각 부휘를 연결해 자세를 추정하는 방식\n",
    "#   작은 것들을 결합\n",
    "\n",
    "# Pose Estimation Model 종류\n",
    "\n",
    "# 1. Pose Net\n",
    "#   Google, 2D 지원 O, 3D 지원 X, 멀티포즈 지원 O, 지원 언어 : JavaScript\n",
    "#   TensorFlow.js를 기반으로 함, 다른 Pose Estimation에 비해 성능이 전체적으로 떨어짐, BodyPix와 결합하여 인간의 실루엣을 추출하는 기능 제공\n",
    "\n",
    "# 2. Blaze Pose\n",
    "#   Google, 2D 지원 O, 2D 포즈 추정 O, 3D 지원 O, 멀티포즈 지원 X, 지원 언어 : Python, JavaScript\n",
    "#   MediaPipe 프레임워크에서 사용되는 딥러닝 기반 포즈 추정 모델, Pose Net 상위 버전, 높은 정확성, 크기가 무겁기에 실시간성이 떨어짐\n",
    "\n",
    "# 3. Move Net\n",
    "#   Google, 2D 지원 O, 3D 지원 O, 멀티포즈 지원 O, 지원 언어: TensorFlow, Python, JavaScript\n",
    "#   MediaPipe 프레임워크에서 사용되는 딥러닝 기반 포즈 추정 모델, 움직임을 중점으로 제작, 모바일 기기에서도 실시간 동작하게 경량화, 높은 정확도와 저전력 소비 보장\n",
    "\n",
    "# 4. MediaPipe Pose\n",
    "#   Google, 2D 지원 O, 2D 포즈 추정 O, 3D 지원 O, 멀티포즈 지원 X, 지원 언어: Python, C++, JavaScript\n",
    "#   Google에서 개발한 오픈소스 라이브러리, 비디오 및 이미지에서 3D 포즈와 트래킹, 페이셜 랜드마크 검출 등 다양한 기능 제공, 높은 정확도와 실시간성 보장\n",
    "\n",
    "# 5. Open Pose\n",
    "#   Carnegie Mellon University, 2D 지원 O, 2D 포즈 추정 O, 3D 지원 O, 멀티포즈 지원 O, C++, Python, Matlab, Java, JavaScript\n",
    "#   인간의 포즈를 비디오나 이미지에서 감지하기 위한 오픈소스 라이브러리, 딥러닝 모델을 기반으로 함, 손가락 추적, 얼굴 감지 등 다양한 기능 제공\n",
    "\n",
    "# 6. Kakao Pose\n",
    "#   Kakao Brain, 2D 지원 O, 2D 포즈 추정 O, 3D 지원 X, 멀티포즈 지원 O, 지원 언어: Python, REST api\n",
    "#   단일 or 다중 인물의 포즈를 추정할 수 있으며 높은 정확도를 가짐, API와 예제 코드를 제공함으로써 편의성이 높음\n",
    "#  이미지의 경우 최대 2MB, 긴 변의 최대 길이는 2048pixel, 최소 320pixel, 동영상의 경우 최대 50MB, 영상 길이 최대 30초까지 무료 분석\n",
    "\n",
    "# 7. Ncloud Pose\n",
    "#   Naver Cloud, 2D 지원 O, 2D 포즈 추정 O, 3D 지원 X, 멀티포즈 지원 X, Python, Java, PHP, C#\n",
    "#   Naver Cloud에서 제공하는 AI 기술 중 하나, API 호출을 통해 손쉽게 사용 가능, 최대 300KB 이미지 데이터를 지원\n",
    "\n",
    "# 8. YOLOv8 Pose\n",
    "#   Ultralytics, 2D 지원 O, 3D 지원 X, 멀티포즈 지원 O, 지원 언어: Python\n",
    "#   YOLO(Object Detection) 기반의 Pose Estimation 모델, 객체 탐지와 자세 추정을 하나의 네트워크에서 동시에 수행, 다중 인물 환경에서 높은 정확도와 안정적인 성능 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "289f29c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe Pose\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture('01_Database/11.mp4')\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('01_Media_Pipe/11_mp.avi', fourcc, fps, (width, height))\n",
    "\n",
    "with mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    enable_segmentation=False,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ") as pose:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret :\n",
    "                break\n",
    "\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            res = pose.process(image_rgb)\n",
    "\n",
    "            if res.pose_landmarks:\n",
    "                mp_draw.draw_landmarks(frame, res.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "            cv2.imshow(\"MediaPipe Pose\", frame)\n",
    "\n",
    "            out.write(frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == 27 : \n",
    "                    break\n",
    "            \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "254411ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolo Pose\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "model = YOLO(\"yolov8s-pose.pt\")\n",
    "\n",
    "cap = cv2.VideoCapture(\"01_Database/11.mp4\")\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "prev_time = 0\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output = cv2.VideoWriter(\"ONLY_SKELETON_YOLO.mp4\", fourcc, fps, (w,h))\n",
    "\n",
    "COCO_CONNECTIONS = [\n",
    "    (5, 7), (7, 9),      # left arm\n",
    "    (6, 8), (8, 10),    # right arm\n",
    "    (5, 6),             # shoulders\n",
    "    (5, 11), (6, 12),   # torso\n",
    "    (11, 12),           # hips\n",
    "    (11, 13), (13, 15), # left leg\n",
    "    (12, 14), (14, 16)  # right leg\n",
    "]\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    skeleton_img = np.zeros_like(frame)\n",
    "    res = model(frame, conf=0.5, verbose=False)\n",
    "\n",
    "    if res[0].keypoints is not None:\n",
    "            kpts = res[0].keypoints.xy.cpu().numpy()\n",
    "            confs = res[0].keypoints.conf.cpu().numpy()\n",
    "\n",
    "            for person_kpts, person_confs in zip(kpts, confs):\n",
    "                    for(x,y),c in zip(person_kpts, person_confs):\n",
    "                            if c > 0.3:\n",
    "                                    cv2.circle(skeleton_img, (int(x), int(y)), 4, (0,255,0),-1)\n",
    "            for i, j in COCO_CONNECTIONS:\n",
    "                if person_confs[i] > 0.3 and person_confs[j] > 0.3:\n",
    "                    pt1 = (int(person_kpts[i][0]), int(person_kpts[i][1]))\n",
    "                    pt2 = (int(person_kpts[j][0]), int(person_kpts[j][1]))\n",
    "                    cv2.line(\n",
    "                        skeleton_img,\n",
    "                        pt1,\n",
    "                        pt2,\n",
    "                        (255, 255, 255),\n",
    "                        2\n",
    "                    )\n",
    "\n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - prev_time) if prev_time != 0 else 0\n",
    "    prev_time = curr_time\n",
    "\n",
    "    cv2.putText(\n",
    "    skeleton_img,\n",
    "    f\"FPS: {fps:.2f}\",\n",
    "             (20, 40),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (0, 255, 0),\n",
    "            2)\n",
    "    \n",
    "    output.write(skeleton_img)\n",
    "\n",
    "    cv2.imshow(\"Yolov8 Pose\", skeleton_img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27 : \n",
    "                    break\n",
    "    \n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c0ab630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe Pose\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture('01_Database/11.mp4')\n",
    "\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('ONLY_SKELETON_MEDIA.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "prev_time = 0\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret :\n",
    "                break\n",
    "\n",
    "            skeleton_img = np.zeros_like(frame)\n",
    "\n",
    "            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            res = pose.process(image_rgb)\n",
    "\n",
    "            if res.pose_landmarks:\n",
    "                mp_draw.draw_landmarks(skeleton_img, res.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "            \n",
    "            curr_time = time.time()\n",
    "            fps = 1 / (curr_time - prev_time) if prev_time != 0 else 0\n",
    "            prev_time = curr_time\n",
    "    \n",
    "            cv2.putText(\n",
    "            skeleton_img,\n",
    "            f\"FPS: {fps:.2f}\",\n",
    "            (20, 40),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            1,\n",
    "            (0, 255, 0),\n",
    "            2)\n",
    "\n",
    "            cv2.imshow(\"MediaPipe Pose\", skeleton_img)\n",
    "\n",
    "            out.write(skeleton_img)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == 27 : \n",
    "                    break\n",
    "            \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
